{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DrQA_question_answering.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co5WFwwA475A"
      },
      "source": [
        "import os\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import functools\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "from torchtext import datasets\r\n",
        "from torchtext.data import Field\r\n",
        "from torchtext.data import BucketIterator\r\n",
        "\r\n",
        "\r\n",
        "SEED = 241"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzKVLyQU5Agi"
      },
      "source": [
        "def seed_everything(seed):\r\n",
        "  random.seed(seed)\r\n",
        "  np.random.seed(seed)\r\n",
        "  torch.manual_seed(seed)\r\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\r\n",
        "\r\n",
        "  if torch.cuda.is_available(): \r\n",
        "    torch.cuda.manual_seed(seed)\r\n",
        "    torch.cuda.manual_seed_all(seed)\r\n",
        "    torch.backends.cudnn.deterministic = True\r\n",
        "    torch.backends.cudnn.benchmark = True\r\n",
        "\r\n",
        "seed_everything(SEED)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fG764r7CXRu"
      },
      "source": [
        "def preprocessing(x):\r\n",
        "  if len(x) > 1 and isinstance(x, list):\r\n",
        "    if ' ' in x[0]:\r\n",
        "      x = ' . '.join(x)\r\n",
        "    else:\r\n",
        "      x = ' '.join(x)\r\n",
        "    x = x.split()\r\n",
        "  return x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG6mqe9jPoyo"
      },
      "source": [
        "TEXT = Field(lower=True,\r\n",
        "             use_vocab=True, \r\n",
        "             sequential=True, \r\n",
        "             init_token='<sos>',\r\n",
        "             eos_token='<eos>',\r\n",
        "             batch_first=True,\r\n",
        "             preprocessing=preprocessing,\r\n",
        "             include_lengths=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQWan0ZaP0F8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65f5fd74-02e1-480f-f8ea-66aa1207c2db"
      },
      "source": [
        "train_data, valid_data, test_data = datasets.BABI20.splits(text_field=TEXT)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading tasks_1-20_v1-2.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "tasks_1-20_v1-2.tar.gz: 100%|██████████| 15.7M/15.7M [00:02<00:00, 6.68MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeNp5-5-P3O-"
      },
      "source": [
        "TEXT.build_vocab(train_data)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg9wfMjI4uZv",
        "outputId": "d95bc57d-f9c5-494e-cb9b-81ac71ac0647"
      },
      "source": [
        "index = 4\r\n",
        "\r\n",
        "print(train_data.examples[index].query) # question\r\n",
        "print(train_data.examples[index].answer) # answer\r\n",
        "print(train_data.examples[index].story) # context"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['where', 'is', 'sandra']\n",
            "['bathroom']\n",
            "['mary', 'moved', 'to', 'the', 'bathroom', '.', 'john', 'went', 'to', 'the', 'hallway', '.', 'daniel', 'went', 'back', 'to', 'the', 'hallway', '.', 'sandra', 'moved', 'to', 'the', 'garden', '.', 'john', 'moved', 'to', 'the', 'office', '.', 'sandra', 'journeyed', 'to', 'the', 'bathroom', '.', 'mary', 'moved', 'to', 'the', 'hallway', '.', 'daniel', 'travelled', 'to', 'the', 'office', '.', 'john', 'went', 'back', 'to', 'the', 'garden', '.', 'john', 'moved', 'to', 'the', 'bedroom']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME8kXII0DxtH"
      },
      "source": [
        "def answer2span(batch_answer, batch_context):\r\n",
        "  result = []\r\n",
        "  candidates = []\r\n",
        "  batch_answer = batch_answer[:, 1:]\r\n",
        "  batch_answer = batch_answer[:, :-1]\r\n",
        "  bs = len(batch_answer)\r\n",
        "  for batch_num in range(bs):\r\n",
        "    candidates.append([])\r\n",
        "    answer = batch_answer[batch_num]\r\n",
        "    context = batch_context[batch_num]\r\n",
        "    for i in range(len(context)):\r\n",
        "      ctx_token = context[i]\r\n",
        "      if answer[0] == ctx_token:\r\n",
        "        if np.allclose(answer, context[i: i + len(answer)]):\r\n",
        "          start = i\r\n",
        "          end = start + len(answer)\r\n",
        "          candidates[batch_num].append((start, end))\r\n",
        "    start, end = candidates[batch_num][-1]\r\n",
        "    result.append([start, end])\r\n",
        "  return result"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbNhsvMPP47f"
      },
      "source": [
        "batch_size = 128\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "\r\n",
        "\r\n",
        "train_iterator = BucketIterator.splits((train_data,), batch_size=batch_size, device=device)[0]\r\n",
        "valid_iterator = BucketIterator.splits((valid_data,), batch_size=batch_size, device=device)[0]\r\n",
        "test_iterator = BucketIterator.splits((test_data,), batch_size=batch_size, device=device)[0]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOAnT5oOGyAd"
      },
      "source": [
        "![DrQa](https://github.com/kushalj001/pytorch-question-answering/blob/master/images/drqaflow.PNG?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSqIXjdWDvyx"
      },
      "source": [
        "class AlignParagraphLayer(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, emb_size):\r\n",
        "    super().__init__()\r\n",
        "    self.linear = nn.Linear(emb_size, emb_size)\r\n",
        "    self.relu = nn.ReLU()\r\n",
        "\r\n",
        "  def forward(self, context_emb, question_emb, question_mask):    \r\n",
        "    # context_emb [bs, seq_len1, emb_dim]\r\n",
        "    # question_emb [bs, seq_len2, emb_dim]\r\n",
        "    # question_mask - padding mask [bs, seq_len2]\r\n",
        "\r\n",
        "    context = self.linear(context_emb)\r\n",
        "    context = self.relu(context)\r\n",
        "    # context_emb [bs, seq_len1, emb_size]\r\n",
        "\r\n",
        "    question = self.linear(question_emb)\r\n",
        "    question = self.relu(question)\r\n",
        "    # question_emb [bs, seq_len2, emb_size]\r\n",
        "\r\n",
        "    question_T = question.permute(0, 2, 1)\r\n",
        "    # question_emb_T [bs, emb_size, seq_len2]\r\n",
        "\r\n",
        "    align_score = torch.bmm(context, question_T)\r\n",
        "    # align_score [bs, seq_len1, seq_len2]\r\n",
        "\r\n",
        "    qtn_mask = question_mask.unsqueeze(1).repeat(1, context_emb.size(1), 1)\r\n",
        "    # qtn_mask [bs, seq_len1, seq_len2]\r\n",
        "\r\n",
        "    align_score = align_score.masked_fill(qtn_mask == 0, -float('inf'))\r\n",
        "    # align_score [bs, seq_len1, seq_len2]\r\n",
        "\r\n",
        "    align_scores_flat = align_score.view(-1, question_T.size(-1))\r\n",
        "    # align_scores_flat [bs * seq_len1, seq_len2]\r\n",
        "\r\n",
        "    alphas = F.softmax(align_scores_flat, dim=1)\r\n",
        "    # alpha [bs * seq_len1, seq_len2]\r\n",
        "\r\n",
        "    alphas = alphas.view(-1, align_score.size(1), align_score.size(2))\r\n",
        "    # alphas [bs, seq_len1, seq_len2]\r\n",
        "\r\n",
        "    alphas_weighted_question = torch.bmm(alphas, question_emb)\r\n",
        "    # alphas_weighted [bs, seq_len1, emb_dim]\r\n",
        "\r\n",
        "    return alphas_weighted_question"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyF4PUOCOHVZ"
      },
      "source": [
        "class StackedBiLSTM(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, emb_dim, hidden_dim, num_layers, dropout):\r\n",
        "    super().__init__()\r\n",
        "    self.num_layers = num_layers\r\n",
        "    self.dropout = dropout\r\n",
        "    self.rnns = nn.ModuleList([nn.LSTM(emb_dim, hidden_dim, num_layers=1, batch_first=True, bidirectional=True) for _ in range(num_layers)])\r\n",
        "    \r\n",
        "  def forward(self, x, x_lens):\r\n",
        "    output = [x]\r\n",
        "    hiddens = []\r\n",
        "    cells = []\r\n",
        "    for layer in self.rnns:\r\n",
        "      x_packed = nn.utils.rnn.pack_padded_sequence(x, x_lens, batch_first=True, enforce_sorted=False)\r\n",
        "      if hiddens:\r\n",
        "        packed_layer_out, (hidden, cell) = layer(x_packed, (hidden, cell))\r\n",
        "      else:\r\n",
        "        packed_layer_out, (hidden, cell) = layer(x_packed)\r\n",
        "      layer_out, _ = nn.utils.rnn.pad_packed_sequence(packed_layer_out, batch_first=True)\r\n",
        "      layer_out = F.dropout(layer_out, p=self.dropout)\r\n",
        "      # layer_out [bs, seq_len, hidden_dim]\r\n",
        "      output.append(layer_out)\r\n",
        "      hiddens.append(hidden)\r\n",
        "      cells.append(cell)\r\n",
        "\r\n",
        "    final_hidden = torch.cat(output[1:], dim=2)\r\n",
        "    # final_hidden [bs, seq_len, hidden_dim*2*num_layers]\r\n",
        "    return final_hidden"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnfGhXR1Ptue"
      },
      "source": [
        "class LinearAttention(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, emb_dim):\r\n",
        "    super().__init__()\r\n",
        "    self.linear = nn.Linear(emb_dim, 1)\r\n",
        "\r\n",
        "  def forward(self, question_emb, question_mask, stacked_bi_lstm_score):\r\n",
        "    # question_emb [bs, seq_len, emb_dim]\r\n",
        "    # question_mask [bs, seq_len]\r\n",
        "    # stacked_bi_lstm_score [bs, seq_len, hidden_dim*2*num_layers]\r\n",
        "    question_emb = self.linear(question_emb)\r\n",
        "    # question_emb [bs, seq_len, 1]\r\n",
        "    question_emb = question_emb.squeeze(2)\r\n",
        "    # question_emb [bs, seq_len]\r\n",
        "    question_emb = question_emb.masked_fill(question_mask == 0, -float('inf'))\r\n",
        "    alphas = F.softmax(question_emb, dim=1)\r\n",
        "    # alphas [bs, seq_len]\r\n",
        "    alphas = alphas.unsqueeze(1)\r\n",
        "    # alphas [bs, 1, seq_len]\r\n",
        "\r\n",
        "    weighted_average = torch.bmm(alphas, stacked_bi_lstm_score)\r\n",
        "    # weighted_average [bs, 1, hidden_dim*2*num_layers]\r\n",
        "    weighted_average = weighted_average.squeeze(1)\r\n",
        "    # weighted_average [bs, hidden_dim*2*num_layers]\r\n",
        "    return weighted_average"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDi1SCJCQs94"
      },
      "source": [
        "class BiLinearAttention(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, question_dim, context_dim):\r\n",
        "    super().__init__()\r\n",
        "    self.context_proj = nn.Linear(question_dim, context_dim)\r\n",
        "\r\n",
        "  def forward(self, context, question, context_mask):\r\n",
        "    # context [bs, seq_len, hidden_dim_ctx*2*num_layers]\r\n",
        "    # question [bs, hidden_dim_qtn*2*num_layers]\r\n",
        "    question = self.context_proj(question)\r\n",
        "    # question [bs, hidden_dim_ctx*2*num_layers]\r\n",
        "    question = question.unsqueeze(2)\r\n",
        "    # question [bs, hidden_dim_ctx*2*num_layers, 1]\r\n",
        "    score = torch.bmm(context, question)\r\n",
        "    # score [bs, seq_len, 1]\r\n",
        "    score = score.squeeze(2)\r\n",
        "    # score [bs, seq_len]\r\n",
        "    score = score.masked_fill(context_mask == 0, -float('inf'))\r\n",
        "    # score = F.softmax(score, dim=1)\r\n",
        "    return score"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxUpRSuJTkep"
      },
      "source": [
        "class DrQA(nn.Module):\r\n",
        "  \r\n",
        "  def __init__(self, voc_size, emb_dim, hidden_dim, num_layers, dropout, device, pad_idx):\r\n",
        "    super().__init__()\r\n",
        "    self.device = device\r\n",
        "    self.context_embedding = nn.Embedding(voc_size, emb_dim, padding_idx=pad_idx)\r\n",
        "    self.question_embedding = nn.Embedding(voc_size, emb_dim, padding_idx=pad_idx)\r\n",
        "    \r\n",
        "    self.context_bilstm = StackedBiLSTM(emb_dim * 2, hidden_dim, num_layers, dropout)\r\n",
        "    self.question_bilstm = StackedBiLSTM(emb_dim, hidden_dim, num_layers, dropout)\r\n",
        "\r\n",
        "    self.align_embedding = AlignParagraphLayer(emb_dim)\r\n",
        "    self.linear_attn = LinearAttention(emb_dim)\r\n",
        "\r\n",
        "    self.start_bilinear_attn = BiLinearAttention(hidden_dim * num_layers * 2, hidden_dim * num_layers * 2)\r\n",
        "    self.end_bilinear_attn = BiLinearAttention(hidden_dim * num_layers * 2, hidden_dim * num_layers * 2)\r\n",
        "\r\n",
        "  def _create_mask(self, text_lens):\r\n",
        "    bs = text_lens.size(0)\r\n",
        "    max_seq_len = torch.max(text_lens)\r\n",
        "    mask = torch.ByteTensor(bs, max_seq_len).fill_(0)\r\n",
        "    for i in range(bs):\r\n",
        "      mask[i, :text_lens[i]] = 1\r\n",
        "    return mask\r\n",
        "\r\n",
        "  def forward(self, context, question, context_lens, question_lens):\r\n",
        "    context_emb = self.context_embedding(context)\r\n",
        "    question_emb = self.context_embedding(question)\r\n",
        "\r\n",
        "    context_mask = self._create_mask(context_lens).to(self.device)\r\n",
        "    question_mask = self._create_mask(question_lens).to(self.device)\r\n",
        "\r\n",
        "    aligned = self.align_embedding(context_emb, question_emb, question_mask)\r\n",
        "    context_bilstm_input = torch.cat([context_emb, aligned], dim=2)\r\n",
        "\r\n",
        "    context_bilstm_output = self.context_bilstm(context_bilstm_input, context_lens)\r\n",
        "    \r\n",
        "    question_bilstm_output = self.question_bilstm(question_emb, question_lens)\r\n",
        "    question_weighted_linear_attn = self.linear_attn(question_emb, question_mask, question_bilstm_output)\r\n",
        "\r\n",
        "    start_prediction = self.start_bilinear_attn(context_bilstm_output, question_weighted_linear_attn, context_mask)\r\n",
        "    end_prediction = self.end_bilinear_attn(context_bilstm_output, question_weighted_linear_attn, context_mask)\r\n",
        "\r\n",
        "    return start_prediction, end_prediction"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i2cJJ6BTR68"
      },
      "source": [
        "# voc_size, emb_dim, hidden_dim, num_layers, dropout, device, pad_idx\r\n",
        "\r\n",
        "config = {\r\n",
        "    'voc_size': len(TEXT.vocab),\r\n",
        "    'emb_dim': 256,\r\n",
        "    'hidden_dim': 256,\r\n",
        "    'num_layers': 3,\r\n",
        "    'dropout': 0.3,\r\n",
        "    'device': device,\r\n",
        "    'pad_idx': TEXT.vocab.stoi[TEXT.pad_token]\r\n",
        "}\r\n",
        "\r\n",
        "drqa = DrQA(**config).to(device)\r\n",
        "start_criterion = nn.CrossEntropyLoss(ignore_index=config['pad_idx']).to(device)\r\n",
        "end_criterion = nn.CrossEntropyLoss(ignore_index=config['pad_idx']).to(device)\r\n",
        "optimizer = torch.optim.Adam(drqa.parameters())"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYcLhS2wWGkJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05890311-d977-4ed6-f6a5-124c3b53e8c4"
      },
      "source": [
        "drqa.train()\r\n",
        "for i in range(20):\r\n",
        "  error = 0\r\n",
        "  for batch in train_iterator:\r\n",
        "\r\n",
        "    optimizer.zero_grad()\r\n",
        "\r\n",
        "    context, context_lens = batch.story\r\n",
        "    question, question_lens = batch.query\r\n",
        "    answer, answer_lens = batch.answer\r\n",
        "    context_lens = context_lens.cpu()\r\n",
        "    question_lens = question_lens.cpu()\r\n",
        "    # print(context.size())\r\n",
        "    # print(question.size())\r\n",
        "    # print(answer.size())\r\n",
        "\r\n",
        "    answer_indexes = answer2span(answer.cpu().numpy(), context.cpu().numpy())\r\n",
        "    answer_indexes = np.array(answer_indexes)\r\n",
        "    start_target = torch.LongTensor(answer_indexes[:, 0]).to(device)\r\n",
        "    end_target = torch.LongTensor(answer_indexes[:, 1]).to(device)\r\n",
        "\r\n",
        "    start, end = drqa(context, question, context_lens, question_lens)\r\n",
        "\r\n",
        "    loss_start = start_criterion(start, start_target)\r\n",
        "    loss_end = end_criterion(end, end_target)\r\n",
        "\r\n",
        "    loss = loss_start + loss_end\r\n",
        "    loss.backward()\r\n",
        "\r\n",
        "    torch.nn.utils.clip_grad_norm_(drqa.parameters(), 10)\r\n",
        "\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    error += loss.detach().cpu().item()\r\n",
        "  print(f'Epoch: {i + 1}, Error: {error / len(train_iterator)}')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Error: 6.7369241416454315\n",
            "Epoch: 2, Error: 3.672165259718895\n",
            "Epoch: 3, Error: 1.950932815670967\n",
            "Epoch: 4, Error: 1.4280065596103668\n",
            "Epoch: 5, Error: 1.250930204987526\n",
            "Epoch: 6, Error: 0.9831048473715782\n",
            "Epoch: 7, Error: 0.889655894599855\n",
            "Epoch: 8, Error: 0.8259633202105761\n",
            "Epoch: 9, Error: 0.7655324898660183\n",
            "Epoch: 10, Error: 0.7403888925909996\n",
            "Epoch: 11, Error: 0.8940124735236168\n",
            "Epoch: 12, Error: 0.9500016644597054\n",
            "Epoch: 13, Error: 0.9352270886301994\n",
            "Epoch: 14, Error: 0.7239808766171336\n",
            "Epoch: 15, Error: 0.9649045541882515\n",
            "Epoch: 16, Error: 1.0642067715525627\n",
            "Epoch: 17, Error: 1.029899850487709\n",
            "Epoch: 18, Error: 0.8221360091120005\n",
            "Epoch: 19, Error: 0.7922133840620518\n",
            "Epoch: 20, Error: 0.69981998950243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9PD7-0XTRBh"
      },
      "source": [
        "def predict(model, question, context, TEXT, device):\r\n",
        "  model.eval()\r\n",
        "\r\n",
        "  question_tokens = [TEXT.init_token] + question.split() + [TEXT.eos_token]\r\n",
        "  context_tokens = [TEXT.init_token] + context.split() + [TEXT.eos_token]\r\n",
        "\r\n",
        "  question_ids = [TEXT.vocab.stoi[token] for token in question_tokens]\r\n",
        "  context_ids = [TEXT.vocab.stoi[token] for token in context_tokens]\r\n",
        "\r\n",
        "  question_tensor = torch.LongTensor([question_ids]).to(device)\r\n",
        "  context_tensor = torch.LongTensor([context_ids]).to(device)\r\n",
        "\r\n",
        "  question_lens = torch.LongTensor([len(question_tokens)])\r\n",
        "  context_lens = torch.LongTensor([len(context_tokens)])\r\n",
        "\r\n",
        "  with torch.no_grad():\r\n",
        "    start_pred, end_pred = model(context_tensor, question_tensor, context_lens, question_lens)\r\n",
        "  \r\n",
        "  start_pred = start_pred.squeeze(0)\r\n",
        "  end_pred = end_pred.squeeze(0)\r\n",
        "\r\n",
        "  start_pos = start_pred.detach().cpu().numpy().argmax()\r\n",
        "  end_pos = end_pred.detach().cpu().numpy().argmax()\r\n",
        "\r\n",
        "  if end_pos < start_pos:\r\n",
        "    start_pos = end_pos - 1\r\n",
        "\r\n",
        "  answer = ' '.join(context_tokens[start_pos:end_pos])\r\n",
        "  return answer"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAsHTgWC71ko",
        "outputId": "8454d059-fe20-46f1-dfdc-75287d31707b"
      },
      "source": [
        "index = 1\r\n",
        "question = ' '.join(train_data.examples[index].query)\r\n",
        "context = ' '.join(train_data.examples[index].story)\r\n",
        "\r\n",
        "print('story:\\t', context)\r\n",
        "print('query:\\t', question)\r\n",
        "print('answer:\\t', predict(drqa, question, context, TEXT, device))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "story:\t mary moved to the bathroom . john went to the hallway . daniel went back to the hallway . sandra moved to the garden\n",
            "query:\t where is daniel\n",
            "answer:\t hallway\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkC0PVuK8GCB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}